{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, callbacks, layers\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation, Add, BatchNormalization, Dropout, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "\n",
    "def mish(x):\n",
    "    return x*tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "def decay(epochs):\n",
    "    init = 1e-3\n",
    "    drop = 10\n",
    "    ratio = 0.9\n",
    "    return max(5e-5, (init * (ratio ** (epochs//drop))))\n",
    "\n",
    "es = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "lrs = callbacks.LearningRateScheduler(decay, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, d_shape, z_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.d_shape = d_shape\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "    \n",
    "    def compile(self, g_optim, d_optim, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.g_optim = g_optim\n",
    "        self.d_optim = d_optim\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    def build_generator(self):\n",
    "        activation = mish\n",
    "        inputs = Input(shape=(self.z_dim, ))\n",
    "        \n",
    "        x = Dense(128, kernel_initializer='he_normal')(inputs)\n",
    "        x = Activation(activation)(x)\n",
    "        x = Dense(256, kernel_initializer='he_normal')(x)\n",
    "        x = Activation(activation)(x)\n",
    "        x = Dense(512, kernel_initializer='he_normal')(x)\n",
    "        x = Activation(activation)(x)\n",
    "        \n",
    "        outputs = Dense(self.d_shape[0], activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "        return Model(inputs, outputs)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        inputs = Input(shape = self.d_shape)\n",
    "        \n",
    "        x = Dense(512)(inputs)\n",
    "        x = Dense(256)(x)\n",
    "        x = Dense(128)(x)\n",
    "        \n",
    "        outputs = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        return Model(inputs, outputs)\n",
    "    \n",
    "    def train_step(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        \n",
    "        noise = self.sampler(batch_size)\n",
    "        \n",
    "        fake_x = self.generator(noise)\n",
    "        all_x = tf.concat([fake_x, x], 0)\n",
    "        \n",
    "        fake_labels = tf.ones((batch_size, 1))*0\n",
    "        real_labels = tf.ones((batch_size, 1))\n",
    "        labels = tf.concat([fake_labels, real_labels], 0)\n",
    "        \n",
    "        # keras official tutorial saids add noise to label is important trick\n",
    "        # labels = 0.05*tf.random.uniform(tf.shape(labels))\n",
    "        \n",
    "        # disc / gen alternatively\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self.discriminator(all_x)\n",
    "            d_loss = self.loss_fn(labels, preds)\n",
    "\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optim.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self.discriminator(self.generator(noise))\n",
    "            g_loss = self.loss_fn(real_labels, preds)\n",
    "            \n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optim.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        return {'d_loss': d_loss, 'g_loss': g_loss}\n",
    "    \n",
    "    def sampler(self, batch_size):\n",
    "        return tf.random.normal(shape=(batch_size, self.z_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "X = np.concatenate([x_train, x_test])\n",
    "X = X.astype(\"float32\") / 255\n",
    "X = X.reshape(X.shape[0], 28*28)\n",
    "\n",
    "# tf.data 공부하고 추가 적용하기\n",
    "# batch_size = 32\n",
    "# data = tf.data.Dataset.from_tensor_slices(X)\n",
    "# data = data.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check list\n",
    "## model architecture ~ for images or complicated data, carefully design\n",
    "## use callbacks to check training progress\n",
    "gan = GAN(X.shape[1:], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 579,728\n",
      "Trainable params: 579,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 566,273\n",
      "Trainable params: 566,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleCallback(callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.score = float('inf')\n",
    "        \n",
    "    def on_epoch_end(self, epoch, losg=None):\n",
    "        '''\n",
    "        if you have val dataset, use them here\n",
    "        (i.e.) \n",
    "        score = criterion(val_y, self.generator.predict(val_X))\n",
    "        if score < self.score:\n",
    "            self.score = score\n",
    "            self.best_weights = self.generator.get_weights()\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def on_train_end(self):\n",
    "        self.generator.set_weights(self.best_weights)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2188/2188 [==============================] - 11s 5ms/step - d_loss: 0.0127 - g_loss: 13.0612\n",
      "Epoch 2/5\n",
      "2188/2188 [==============================] - 16s 7ms/step - d_loss: 0.0130 - g_loss: 24.5690\n",
      "Epoch 3/5\n",
      "2188/2188 [==============================] - 10s 4ms/step - d_loss: 0.0113 - g_loss: 23.9610\n",
      "Epoch 4/5\n",
      "2188/2188 [==============================] - 9s 4ms/step - d_loss: 9.7195e-05 - g_loss: 10.9079\n",
      "Epoch 5/5\n",
      "2188/2188 [==============================] - 10s 4ms/step - d_loss: 0.0053 - g_loss: 24.2541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x214c274d208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.compile(\n",
    "    optimizers.Adam(2e-4),\n",
    "    optimizers.Adam(2e-4),\n",
    "    keras.losses.BinaryCrossentropy()\n",
    "           )\n",
    "\n",
    "gan.fit(X, epochs=5)\n",
    "\n",
    "# TODO\n",
    "## custom callback to check training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
