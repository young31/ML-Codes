{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, callbacks, layers\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Activation, Add, BatchNormalization, Dropout, Input\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "\n",
    "def mish(x):\n",
    "    return x*tf.math.tanh(tf.math.softplus(x))\n",
    "\n",
    "def decay(epochs):\n",
    "    init = 1e-3\n",
    "    drop = 10\n",
    "    ratio = 0.9\n",
    "    return max(5e-5, (init * (ratio ** (epochs//drop))))\n",
    "\n",
    "es = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "lrs = callbacks.LearningRateScheduler(decay, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cGAN(keras.Model):\n",
    "    def __init__(self, x_dim, y_dim, z_dim):\n",
    "        super(cGAN, self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.d_steps = 4\n",
    "        self.gp_weight = 10\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "    \n",
    "    def compile(self, g_optim, d_optim, g_loss_fn, d_loss_fn):\n",
    "        super(cGAN, self).compile()\n",
    "        self.g_optim = g_optim\n",
    "        self.d_optim = d_optim\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        \n",
    "    def build_generator(self):\n",
    "        activation = mish\n",
    "        inputs_z = Input(shape=(self.z_dim, ))\n",
    "        inputs_x = Input(shape=(self.x_dim, ))\n",
    "        \n",
    "        x = Concatenate()([inputs_z, inputs_x])\n",
    "        \n",
    "        x = Dense(128, kernel_initializer='he_normal')(x)\n",
    "        x = Activation(activation)(x)\n",
    "        x = Dense(64, kernel_initializer='he_normal')(x)\n",
    "        x = Activation(activation)(x)\n",
    "\n",
    "        outputs = Dense(self.y_dim, kernel_initializer='he_normal')(x)\n",
    "        return Model([inputs_z, inputs_x], outputs)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        inputs_x = Input(shape = (self.x_dim, ))\n",
    "        inputs_y = Input(shape = (self.y_dim, ))\n",
    "\n",
    "        x = Concatenate()([inputs_x, inputs_y])\n",
    "        x = Dense(64, activation=mish)(x)\n",
    "        x = Dense(32, activation=mish)(x)\n",
    "        \n",
    "        outputs = Dense(1)(x)\n",
    "        \n",
    "        return Model([inputs_x, inputs_y], outputs)\n",
    "    \n",
    "    def gradient_penalty(self, batch_size, x, y, y_pred):\n",
    "        alpha = tf.random.normal([batch_size, 1], 0.0, 1.0)\n",
    "        diff = y - y_pred\n",
    "        interpolated = y + alpha * diff\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator([x, interpolated], training=True)\n",
    "    \n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calcuate the norm of the gradients\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        \n",
    "        real_label = tf.ones((batch_size, 1))\n",
    "        fake_label = tf.ones((batch_size, 1))*-1\n",
    "        labels = tf.concat([real_label, fake_label], -1)\n",
    "        \n",
    "        for i in range(self.d_steps):\n",
    "            noise = self.sampler(batch_size)\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = self.generator([noise, x])\n",
    "                fake_validity = self.discriminator([x, y_pred])\n",
    "                real_validity = self.discriminator([x, y])\n",
    "                validity = tf.concat([real_validity, fake_validity], -1)\n",
    "\n",
    "                cost = self.d_loss_fn(real_validity, fake_validity)\n",
    "                gp = self.gradient_penalty(batch_size, x, y, y_pred)\n",
    "                \n",
    "                d_loss = cost + gp*self.gp_weight\n",
    "                \n",
    "            grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            self.d_optim.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n",
    "            \n",
    "            \n",
    "        noise = self.sampler(batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_preds = self.generator([noise, x])\n",
    "            validity = self.discriminator([x, y_preds])\n",
    "            g_loss = self.g_loss_fn(validity)\n",
    "            \n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optim.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        return {'d_loss': d_loss, 'g_loss': g_loss}\n",
    "    \n",
    "    def sampler(self, batch_size):\n",
    "        return tf.random.normal((batch_size, self.z_dim), 0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(0, 1, (1000, 128))\n",
    "y = np.random.normal(0, 1, (1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_loss(preds):\n",
    "    return -tf.reduce_mean(preds)\n",
    "\n",
    "def disc_loss(y, y_pred):\n",
    "    real_loss = tf.reduce_mean(y)\n",
    "    fake_loss = tf.reduce_mean(y_pred)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "gan = cGAN(128, 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(\n",
    "    optimizers.RMSprop(2e-4),\n",
    "    optimizers.RMSprop(2e-4),\n",
    "    gen_loss,\n",
    "    disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSECallback(callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # TODO: redefine validation data\n",
    "        if epoch % 4 == 0:\n",
    "            true = y\n",
    "            noise = self.model.sampler(y.shape[0])\n",
    "            pred = self.model.generator.predict([noise, X])\n",
    "            print(f'\\n epoch {epoch} error')\n",
    "            print(mse(y, pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch 0 error\n",
      "3.1085530466622897\n",
      "\n",
      " epoch 4 error\n",
      "2.5773129929305663\n",
      "\n",
      " epoch 8 error\n",
      "2.362732527255694\n",
      "\n",
      " epoch 12 error\n",
      "1.8791958815347187\n",
      "\n",
      " epoch 16 error\n",
      "1.7382884525368474\n",
      "\n",
      " epoch 20 error\n",
      "1.654639301853771\n",
      "\n",
      " epoch 24 error\n",
      "1.729948321400752\n",
      "\n",
      " epoch 28 error\n",
      "1.8014968250443129\n",
      "\n",
      " epoch 32 error\n",
      "1.9001921689319279\n",
      "\n",
      " epoch 36 error\n",
      "1.9271275913882788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a08114dcc8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.fit(X, y, \n",
    "        epochs=40,\n",
    "       callbacks=[MSECallback()],\n",
    "       verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 158)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          20352       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         activation_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 29,258\n",
      "Trainable params: 29,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 138)          0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8896        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,009\n",
      "Trainable params: 11,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
