{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "data, target = data['data'], data['target']\n",
    "\n",
    "tr_X, val_X, tr_y, val_y = train_test_split(data, target, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check List\n",
    "## check objective ~ reg/clf\n",
    "## check loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = {\n",
    "    'num_leaves': (100, 800), \n",
    "    'min_data_in_leaf': (0, 150),\n",
    "    'bagging_fraction' : (0.3, 0.9),\n",
    "    'feature_fraction' : (0.3, 0.9),\n",
    "#     'learning_rate': (0.01, 1),\n",
    "    'min_child_weight': (0.01, 3),   \n",
    "    'reg_alpha': (0.1, 3), \n",
    "    'reg_lambda': (0.1, 3),\n",
    "    'max_depth':(6, 23),\n",
    "    'n_estimators': (64, 512)\n",
    "}\n",
    "\n",
    "def build_xgb(x, y, init_points=15, n_iter=0, param=True, verbose=2):\n",
    "    train_X, test_X, train_y, test_y = train_test_split(x, y, test_size=0.3, random_state=12, shuffle=True)\n",
    "    def XGB_bayesian(\n",
    "        #learning_rate,\n",
    "        num_leaves, \n",
    "        bagging_fraction,\n",
    "        feature_fraction,\n",
    "        min_child_weight, \n",
    "        min_data_in_leaf,\n",
    "        max_depth,\n",
    "        reg_alpha,\n",
    "        reg_lambda,\n",
    "        n_estimators\n",
    "         ):\n",
    "        # LightGBM expects next three parameters need to be integer. \n",
    "        num_leaves = int(num_leaves)\n",
    "        min_data_in_leaf = int(min_data_in_leaf)\n",
    "        max_depth = int(max_depth)\n",
    "\n",
    "        assert type(num_leaves) == int\n",
    "        assert type(min_data_in_leaf) == int\n",
    "        assert type(max_depth) == int\n",
    "\n",
    "\n",
    "        params = {\n",
    "                  'num_leaves': num_leaves, \n",
    "                  'min_data_in_leaf': min_data_in_leaf,\n",
    "                  'min_child_weight': min_child_weight,\n",
    "                  'bagging_fraction' : bagging_fraction,\n",
    "                  'feature_fraction' : feature_fraction,\n",
    "                  'learning_rate' : 0.05,\n",
    "                  'max_depth': max_depth,\n",
    "                  'reg_alpha': reg_alpha,\n",
    "                  'reg_lambda': reg_lambda,\n",
    "                  'objective': 'binary:logistic',\n",
    "                  'save_binary': True,\n",
    "                  'seed': SEED,\n",
    "                  'feature_fraction_seed': SEED,\n",
    "                  'bagging_seed': SEED,\n",
    "                  'drop_seed': SEED,\n",
    "                  'data_random_seed': SEED,\n",
    "                  'verbose': 1,\n",
    "                  'is_unbalance': True,\n",
    "                  'boost_from_average': True,\n",
    "                  'metric':'auc',\n",
    "                  'n_estimators': int(n_estimators),\n",
    "                  'tree_method ': 'gpu_hist' # check gpu availability\n",
    "        }    \n",
    "\n",
    "        ## set clf options\n",
    "        clf = xgb.XGBClassifier(**params).fit(train_X, train_y)\n",
    "        score = roc_auc_score(test_y, clf.predict_proba(test_X)[:,1])\n",
    "        return score\n",
    "    \n",
    "    optimizer = BayesianOptimization(XGB_bayesian, bounds, random_state=42, verbose=verbose)\n",
    "    init_points = init_points\n",
    "    n_iter = n_iter\n",
    "\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "    \n",
    "    param_xgb = {\n",
    "        'min_data_in_leaf': int(optimizer.max['params']['min_data_in_leaf']), \n",
    "        'num_leaves': int(optimizer.max['params']['num_leaves']), \n",
    "        'learning_rate': 0.05,\n",
    "        'min_child_weight': optimizer.max['params']['min_child_weight'],\n",
    "        'bagging_fraction': optimizer.max['params']['bagging_fraction'], \n",
    "        'feature_fraction': optimizer.max['params']['feature_fraction'],\n",
    "        'reg_lambda': optimizer.max['params']['reg_lambda'],\n",
    "        'reg_alpha': optimizer.max['params']['reg_alpha'],\n",
    "        'max_depth': int(optimizer.max['params']['max_depth']), \n",
    "        'objective': 'binary:logistic',\n",
    "        'save_binary': True,\n",
    "        'seed': SEED,\n",
    "        'feature_fraction_seed': SEED,\n",
    "        'bagging_seed': SEED,\n",
    "        'drop_seed': SEED,\n",
    "        'data_random_seed': SEED,\n",
    "        'verbose': 1,\n",
    "        'is_unbalance': True,\n",
    "        'boost_from_average': True,\n",
    "        'metric':'auc',\n",
    "        'n_estimators': int(optimizer.max['params']['n_estimators']),\n",
    "         'tree_method ': 'gpu_hist' # check gpu availability\n",
    "    }\n",
    "\n",
    "    params = param_xgb.copy()\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(**params)\n",
    "    xgb_clf.fit(x, y)\n",
    "    \n",
    "    if param:\n",
    "        return xgb_clf, params, optimizer.max['target']\n",
    "    else:\n",
    "        return xgb_clf, optimizer.max['target']\n",
    "\n",
    "def build_lgb(x, y, init_points=15, n_iter=0, param=True, verbose=2):\n",
    "    train_X, test_X, train_y, test_y = train_test_split(x, y, test_size=0.3, random_state=12, shuffle=True)\n",
    "    def LGB_bayesian(\n",
    "        #learning_rate,\n",
    "        num_leaves, \n",
    "        bagging_fraction,\n",
    "        feature_fraction,\n",
    "        min_child_weight, \n",
    "        min_data_in_leaf,\n",
    "        max_depth,\n",
    "        reg_alpha,\n",
    "        reg_lambda,\n",
    "        n_estimators\n",
    "         ):\n",
    "        # LightGBM expects next three parameters need to be integer. \n",
    "        num_leaves = int(num_leaves)\n",
    "        min_data_in_leaf = int(min_data_in_leaf)\n",
    "        max_depth = int(max_depth)\n",
    "\n",
    "        assert type(num_leaves) == int\n",
    "        assert type(min_data_in_leaf) == int\n",
    "        assert type(max_depth) == int\n",
    "\n",
    "\n",
    "        params = {\n",
    "                  'num_leaves': num_leaves, \n",
    "                  'min_data_in_leaf': min_data_in_leaf,\n",
    "                  'min_child_weight': min_child_weight,\n",
    "                  'bagging_fraction' : bagging_fraction,\n",
    "                  'feature_fraction' : feature_fraction,\n",
    "                  'learning_rate' : 0.05,\n",
    "                  'max_depth': max_depth,\n",
    "                  'reg_alpha': reg_alpha,\n",
    "                  'reg_lambda': reg_lambda,\n",
    "                  'objective': 'cross_entropy',\n",
    "                  'save_binary': True,\n",
    "                  'seed': SEED,\n",
    "                  'feature_fraction_seed': SEED,\n",
    "                  'bagging_seed': SEED,\n",
    "                  'drop_seed': SEED,\n",
    "                  'data_random_seed': SEED,\n",
    "                  'boosting': 'gbdt', ## some get better result using 'dart'\n",
    "                  'verbose': 1,\n",
    "                  'is_unbalance': True,\n",
    "                  'boost_from_average': True,\n",
    "                  'metric':'auc',\n",
    "                  'n_estimators': int(n_estimators),\n",
    "                  'tree_learner ': 'voting'\n",
    "        }    \n",
    "\n",
    "        ## set clf options\n",
    "        clf = lgb.LGBMClassifier(**params).fit(train_X, train_y)\n",
    "        score = roc_auc_score(test_y, clf.predict_proba(test_X)[:,1])\n",
    "        return score\n",
    "    \n",
    "    optimizer = BayesianOptimization(LGB_bayesian, bounds, random_state=42, verbose=verbose)\n",
    "    init_points = init_points\n",
    "    n_iter = n_iter\n",
    "\n",
    "    optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "    \n",
    "    param_lgb = {\n",
    "        'min_data_in_leaf': int(optimizer.max['params']['min_data_in_leaf']), \n",
    "        'num_leaves': int(optimizer.max['params']['num_leaves']), \n",
    "        'learning_rate': 0.05,\n",
    "        'min_child_weight': optimizer.max['params']['min_child_weight'],\n",
    "        'bagging_fraction': optimizer.max['params']['bagging_fraction'], \n",
    "        'feature_fraction': optimizer.max['params']['feature_fraction'],\n",
    "        'reg_lambda': optimizer.max['params']['reg_lambda'],\n",
    "        'reg_alpha': optimizer.max['params']['reg_alpha'],\n",
    "        'max_depth': int(optimizer.max['params']['max_depth']), \n",
    "        'objective': 'cross_entropy',\n",
    "        'save_binary': True,\n",
    "        'seed': SEED,\n",
    "        'feature_fraction_seed': SEED,\n",
    "        'bagging_seed': SEED,\n",
    "        'drop_seed': SEED,\n",
    "        'data_random_seed': SEED,\n",
    "        'boosting_type': 'gbdt',  # also consider 'dart'\n",
    "        'verbose': 1,\n",
    "        'is_unbalance': True,\n",
    "        'boost_from_average': True,\n",
    "        'metric':'auc',\n",
    "        'n_estimators': int(optimizer.max['params']['n_estimators']),\n",
    "        'tree_learner ': 'voting'\n",
    "    }\n",
    "\n",
    "    params = param_lgb.copy()\n",
    "    \n",
    "    lgb_clf = lgb.LGBMClassifier(**params)\n",
    "    lgb_clf.fit(x, y)\n",
    "    \n",
    "    if param:\n",
    "        return lgb_clf, params, optimizer.max['target']\n",
    "    else:\n",
    "        return lgb_clf, optimizer.max['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | max_depth | min_ch... | min_da... | n_esti... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9963  \u001b[0m | \u001b[0m 0.5247  \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 18.44   \u001b[0m | \u001b[0m 1.8     \u001b[0m | \u001b[0m 23.4    \u001b[0m | \u001b[0m 133.9   \u001b[0m | \u001b[0m 140.7   \u001b[0m | \u001b[0m 2.612   \u001b[0m | \u001b[0m 1.843   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9949  \u001b[0m | \u001b[0m 0.7248  \u001b[0m | \u001b[0m 0.3124  \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 2.499   \u001b[0m | \u001b[0m 31.85   \u001b[0m | \u001b[0m 145.5   \u001b[0m | \u001b[0m 228.4   \u001b[0m | \u001b[0m 0.9823  \u001b[0m | \u001b[0m 1.622   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9953  \u001b[0m | \u001b[0m 0.5592  \u001b[0m | \u001b[0m 0.4747  \u001b[0m | \u001b[0m 16.4    \u001b[0m | \u001b[0m 0.4271  \u001b[0m | \u001b[0m 43.82   \u001b[0m | \u001b[0m 228.1   \u001b[0m | \u001b[0m 419.2   \u001b[0m | \u001b[0m 2.377   \u001b[0m | \u001b[0m 0.6791  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9956  \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 0.6554  \u001b[0m | \u001b[0m 6.79    \u001b[0m | \u001b[0m 1.827   \u001b[0m | \u001b[0m 25.58   \u001b[0m | \u001b[0m 93.14   \u001b[0m | \u001b[0m 764.2   \u001b[0m | \u001b[0m 2.9     \u001b[0m | \u001b[0m 2.444   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.4828  \u001b[0m | \u001b[0m 0.3586  \u001b[0m | \u001b[0m 17.63   \u001b[0m | \u001b[0m 1.326   \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 285.8   \u001b[0m | \u001b[0m 124.1   \u001b[0m | \u001b[0m 2.737   \u001b[0m | \u001b[0m 0.8505  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9965  \u001b[0m | \u001b[95m 0.6975  \u001b[0m | \u001b[95m 0.487   \u001b[0m | \u001b[95m 14.84   \u001b[0m | \u001b[95m 1.645   \u001b[0m | \u001b[95m 27.73   \u001b[0m | \u001b[95m 498.4   \u001b[0m | \u001b[95m 642.6   \u001b[0m | \u001b[95m 2.825   \u001b[0m | \u001b[95m 2.695   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9951  \u001b[0m | \u001b[0m 0.6587  \u001b[0m | \u001b[0m 0.8531  \u001b[0m | \u001b[0m 7.504   \u001b[0m | \u001b[0m 0.596   \u001b[0m | \u001b[0m 6.784   \u001b[0m | \u001b[0m 209.7   \u001b[0m | \u001b[0m 372.1   \u001b[0m | \u001b[0m 0.8869  \u001b[0m | \u001b[0m 2.503   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9949  \u001b[0m | \u001b[0m 0.5141  \u001b[0m | \u001b[0m 0.4686  \u001b[0m | \u001b[0m 15.23   \u001b[0m | \u001b[0m 0.4314  \u001b[0m | \u001b[0m 120.3   \u001b[0m | \u001b[0m 97.4    \u001b[0m | \u001b[0m 790.8   \u001b[0m | \u001b[0m 2.34    \u001b[0m | \u001b[0m 0.6763  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9949  \u001b[0m | \u001b[0m 0.3033  \u001b[0m | \u001b[0m 0.7893  \u001b[0m | \u001b[0m 18.02   \u001b[0m | \u001b[0m 2.19    \u001b[0m | \u001b[0m 115.7   \u001b[0m | \u001b[0m 97.17   \u001b[0m | \u001b[0m 350.9   \u001b[0m | \u001b[0m 0.436   \u001b[0m | \u001b[0m 2.603   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9951  \u001b[0m | \u001b[0m 0.674   \u001b[0m | \u001b[0m 0.4985  \u001b[0m | \u001b[0m 7.08    \u001b[0m | \u001b[0m 0.9398  \u001b[0m | \u001b[0m 48.78   \u001b[0m | \u001b[0m 390.9   \u001b[0m | \u001b[0m 546.3   \u001b[0m | \u001b[0m 2.673   \u001b[0m | \u001b[0m 1.469   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9956  \u001b[0m | \u001b[0m 0.3718  \u001b[0m | \u001b[0m 0.7279  \u001b[0m | \u001b[0m 18.93   \u001b[0m | \u001b[0m 1.688   \u001b[0m | \u001b[0m 115.6   \u001b[0m | \u001b[0m 285.2   \u001b[0m | \u001b[0m 465.9   \u001b[0m | \u001b[0m 1.34    \u001b[0m | \u001b[0m 0.1737  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9953  \u001b[0m | \u001b[0m 0.3647  \u001b[0m | \u001b[0m 0.3189  \u001b[0m | \u001b[0m 16.82   \u001b[0m | \u001b[0m 0.9499  \u001b[0m | \u001b[0m 76.29   \u001b[0m | \u001b[0m 470.6   \u001b[0m | \u001b[0m 274.5   \u001b[0m | \u001b[0m 1.29    \u001b[0m | \u001b[0m 2.291   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9953  \u001b[0m | \u001b[0m 0.4373  \u001b[0m | \u001b[0m 0.3462  \u001b[0m | \u001b[0m 10.93   \u001b[0m | \u001b[0m 0.4921  \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 426.0   \u001b[0m | \u001b[0m 543.4   \u001b[0m | \u001b[0m 2.627   \u001b[0m | \u001b[0m 2.431   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.4119  \u001b[0m | \u001b[0m 0.8355  \u001b[0m | \u001b[0m 15.17   \u001b[0m | \u001b[0m 2.424   \u001b[0m | \u001b[0m 134.4   \u001b[0m | \u001b[0m 206.5   \u001b[0m | \u001b[0m 177.0   \u001b[0m | \u001b[0m 0.761   \u001b[0m | \u001b[0m 1.339   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9958  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.8164  \u001b[0m | \u001b[0m 6.118   \u001b[0m | \u001b[0m 1.537   \u001b[0m | \u001b[0m 62.61   \u001b[0m | \u001b[0m 163.5   \u001b[0m | \u001b[0m 183.9   \u001b[0m | \u001b[0m 1.079   \u001b[0m | \u001b[0m 2.834   \u001b[0m |\n",
      "=====================================================================================================================================\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | min_ch... | min_da... | n_esti... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9963  \u001b[0m | \u001b[0m 0.5247  \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 18.44   \u001b[0m | \u001b[0m 1.8     \u001b[0m | \u001b[0m 23.4    \u001b[0m | \u001b[0m 133.9   \u001b[0m | \u001b[0m 140.7   \u001b[0m | \u001b[0m 2.612   \u001b[0m | \u001b[0m 1.843   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.996   \u001b[0m | \u001b[0m 0.7248  \u001b[0m | \u001b[0m 0.3124  \u001b[0m | \u001b[0m 22.49   \u001b[0m | \u001b[0m 2.499   \u001b[0m | \u001b[0m 31.85   \u001b[0m | \u001b[0m 145.5   \u001b[0m | \u001b[0m 228.4   \u001b[0m | \u001b[0m 0.9823  \u001b[0m | \u001b[0m 1.622   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9965  \u001b[0m | \u001b[95m 0.5592  \u001b[0m | \u001b[95m 0.4747  \u001b[0m | \u001b[95m 16.4    \u001b[0m | \u001b[95m 0.4271  \u001b[0m | \u001b[95m 43.82   \u001b[0m | \u001b[95m 228.1   \u001b[0m | \u001b[95m 419.2   \u001b[0m | \u001b[95m 2.377   \u001b[0m | \u001b[95m 0.6791  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9963  \u001b[0m | \u001b[0m 0.6085  \u001b[0m | \u001b[0m 0.6554  \u001b[0m | \u001b[0m 6.79    \u001b[0m | \u001b[0m 1.827   \u001b[0m | \u001b[0m 25.58   \u001b[0m | \u001b[0m 93.14   \u001b[0m | \u001b[0m 764.2   \u001b[0m | \u001b[0m 2.9     \u001b[0m | \u001b[0m 2.444   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9963  \u001b[0m | \u001b[0m 0.4828  \u001b[0m | \u001b[0m 0.3586  \u001b[0m | \u001b[0m 17.63   \u001b[0m | \u001b[0m 1.326   \u001b[0m | \u001b[0m 18.31   \u001b[0m | \u001b[0m 285.8   \u001b[0m | \u001b[0m 124.1   \u001b[0m | \u001b[0m 2.737   \u001b[0m | \u001b[0m 0.8505  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.996   \u001b[0m | \u001b[0m 0.6975  \u001b[0m | \u001b[0m 0.487   \u001b[0m | \u001b[0m 14.84   \u001b[0m | \u001b[0m 1.645   \u001b[0m | \u001b[0m 27.73   \u001b[0m | \u001b[0m 498.4   \u001b[0m | \u001b[0m 642.6   \u001b[0m | \u001b[0m 2.825   \u001b[0m | \u001b[0m 2.695   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.997   \u001b[0m | \u001b[95m 0.6587  \u001b[0m | \u001b[95m 0.8531  \u001b[0m | \u001b[95m 7.504   \u001b[0m | \u001b[95m 0.596   \u001b[0m | \u001b[95m 6.784   \u001b[0m | \u001b[95m 209.7   \u001b[0m | \u001b[95m 372.1   \u001b[0m | \u001b[95m 0.8869  \u001b[0m | \u001b[95m 2.503   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9957  \u001b[0m | \u001b[0m 0.5141  \u001b[0m | \u001b[0m 0.4686  \u001b[0m | \u001b[0m 15.23   \u001b[0m | \u001b[0m 0.4314  \u001b[0m | \u001b[0m 120.3   \u001b[0m | \u001b[0m 97.4    \u001b[0m | \u001b[0m 790.8   \u001b[0m | \u001b[0m 2.34    \u001b[0m | \u001b[0m 0.6763  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.997   \u001b[0m | \u001b[0m 0.3033  \u001b[0m | \u001b[0m 0.7893  \u001b[0m | \u001b[0m 18.02   \u001b[0m | \u001b[0m 2.19    \u001b[0m | \u001b[0m 115.7   \u001b[0m | \u001b[0m 97.17   \u001b[0m | \u001b[0m 350.9   \u001b[0m | \u001b[0m 0.436   \u001b[0m | \u001b[0m 2.603   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9965  \u001b[0m | \u001b[0m 0.674   \u001b[0m | \u001b[0m 0.4985  \u001b[0m | \u001b[0m 7.08    \u001b[0m | \u001b[0m 0.9398  \u001b[0m | \u001b[0m 48.78   \u001b[0m | \u001b[0m 390.9   \u001b[0m | \u001b[0m 546.3   \u001b[0m | \u001b[0m 2.673   \u001b[0m | \u001b[0m 1.469   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.9986  \u001b[0m | \u001b[95m 0.3718  \u001b[0m | \u001b[95m 0.7279  \u001b[0m | \u001b[95m 18.93   \u001b[0m | \u001b[95m 1.688   \u001b[0m | \u001b[95m 115.6   \u001b[0m | \u001b[95m 285.2   \u001b[0m | \u001b[95m 465.9   \u001b[0m | \u001b[95m 1.34    \u001b[0m | \u001b[95m 0.1737  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9974  \u001b[0m | \u001b[0m 0.3647  \u001b[0m | \u001b[0m 0.3189  \u001b[0m | \u001b[0m 16.82   \u001b[0m | \u001b[0m 0.9499  \u001b[0m | \u001b[0m 76.29   \u001b[0m | \u001b[0m 470.6   \u001b[0m | \u001b[0m 274.5   \u001b[0m | \u001b[0m 1.29    \u001b[0m | \u001b[0m 2.291   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9949  \u001b[0m | \u001b[0m 0.4373  \u001b[0m | \u001b[0m 0.3462  \u001b[0m | \u001b[0m 10.93   \u001b[0m | \u001b[0m 0.4921  \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 426.0   \u001b[0m | \u001b[0m 543.4   \u001b[0m | \u001b[0m 2.627   \u001b[0m | \u001b[0m 2.431   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9949  \u001b[0m | \u001b[0m 0.4119  \u001b[0m | \u001b[0m 0.8355  \u001b[0m | \u001b[0m 15.17   \u001b[0m | \u001b[0m 2.424   \u001b[0m | \u001b[0m 134.4   \u001b[0m | \u001b[0m 206.5   \u001b[0m | \u001b[0m 177.0   \u001b[0m | \u001b[0m 0.761   \u001b[0m | \u001b[0m 1.339   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9974  \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.8164  \u001b[0m | \u001b[0m 6.118   \u001b[0m | \u001b[0m 1.537   \u001b[0m | \u001b[0m 62.61   \u001b[0m | \u001b[0m 163.5   \u001b[0m | \u001b[0m 183.9   \u001b[0m | \u001b[0m 1.079   \u001b[0m | \u001b[0m 2.834   \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgb_clf, score = build_xgb(tr_X, tr_y, param=False)\n",
    "xgb_clf, score = build_lgb(tr_X, tr_y, param=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=9, random_state=SEED)\n",
    "pca = PCA(4)\n",
    "\n",
    "models = [\n",
    "    [lgb_clf, xgb_clf, pca], # pca 등도 이 단계에서 추가 가능\n",
    "    [rf]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "Input Dimensionality 30 at Level 0 \n",
      "3 models included in Level 0 \n",
      "Fold 1/3 , model 0 , auc===0.985897 \n",
      "Fold 1/3 , model 1 , auc===0.976749 \n",
      "=========== end of fold 1 in level 0 ===========\n",
      "Fold 2/3 , model 0 , auc===0.992042 \n",
      "Fold 2/3 , model 1 , auc===0.986737 \n",
      "=========== end of fold 2 in level 0 ===========\n",
      "Fold 3/3 , model 0 , auc===0.988824 \n",
      "Fold 3/3 , model 1 , auc===0.991961 \n",
      "=========== end of fold 3 in level 0 ===========\n",
      "Level 0, model 0 , auc===0.988921 \n",
      "Level 0, model 1 , auc===0.985149 \n",
      "Output dimensionality of level 0 is 6 \n",
      "====================== End of Level 0 ======================\n",
      " level 0 lasted 6.621325 seconds \n",
      "====================== Start of Level 1 ======================\n",
      "Input Dimensionality 6 at Level 1 \n",
      "1 models included in Level 1 \n",
      "Fold 1/3 , model 0 , auc===0.968363 \n",
      "=========== end of fold 1 in level 1 ===========\n",
      "Fold 2/3 , model 0 , auc===0.977896 \n",
      "=========== end of fold 2 in level 1 ===========\n",
      "Fold 3/3 , model 0 , auc===0.981275 \n",
      "=========== end of fold 3 in level 1 ===========\n",
      "Level 1, model 0 , auc===0.975844 \n",
      "Output dimensionality of level 1 is 1 \n",
      "====================== End of Level 1 ======================\n",
      " level 1 lasted 1.366052 seconds \n",
      "====================== End of fit ======================\n",
      " fit() lasted 7.989347 seconds \n"
     ]
    }
   ],
   "source": [
    "stk_clf = StackNetClassifier(models, \n",
    "                             metric='auc',\n",
    "                            random_state=SEED, n_jobs=-1,\n",
    "                            verbose=2)\n",
    "\n",
    "stk_clf.fit(tr_X, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "1 estimators included in Level 0 \n",
      "====================== Start of Level 1 ======================\n",
      "1 estimators included in Level 1 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9882083196855551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(val_y, stk_clf.predict_proba(val_X)[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
